
\section{Submodularity}
In this section, we first give several equivalent definitions of submodularity, and then we introduce several fundamental properties of submodular functions. We also discuss various constraints that occur frequently in submodular optimization problems. In the last part of this section, we cover algorithms that solve constrained submodular maximization problems with theoretical approximation guarantee. 

\subsection{Definitions}
There are many equivalent definitions, and we will discuss three of them in this section. 

\begin{definition}[submodular concave]
  \label{def:sub-concave}
  A function $f:~2^V \rightarrow \bbR$ is \emRed{submodular} if for any $A, B \subseteq V$, we have that:
  \begin{equation}
    \label{eq:sub-concave}
    f(A) + f(B) \geq f(A \cup B) + f(A \cap B).
  \end{equation}
\end{definition}

An alternate equivalent definition is more interpretable in many situations,

\begin{definition}[diminishing returns]
  \label{def:sub-diminishing}
  A function $f: 2^V \rightarrow \bbR$ is \emRed{submodular} if for any $A \subseteq B \subset V$, and $v \in V\backslash B$, we have that:
  \begin{equation}
    \label{eq:sub-diminishing}
    f(A + v) - f(A) \geq f(B + v) - f(B).
  \end{equation}
\end{definition}

Intuitively, this definition requires that the incremental ``gain'' of adding a new element $v$ decreases (diminishes) as the base set grows from $A$ to $B$. We will see that this property is actually shared by many real-world phenomenons.

It turns out that a stronger but equivalent statement can also serve as the definition of a submodular function,

\begin{definition}[group diminishing returns]
  \label{def:sub-diminishing-group}
  A function $f: 2^V \rightarrow \bbR$ is \emRed{submodular} if for any $A \subseteq B \subset V$, and $C \subseteq V\backslash B$, we have that:
  \begin{equation}
    \label{eq:sub-diminishing-group}
    f(A \cup C) - f(A) \geq f(B \cup C) - f(B).
  \end{equation}
\end{definition}


\subsection{Modularity and Supermodularity}
We also briefly mention modularity and supermodularity here. These two concepts are closely related to submodularity. 

A function $f: 2^V \rightarrow \bbR$ is modular if we replace inequality by equality in Definition \ref{def:sub-diminishing} (or any of other two). Formally, 

\begin{definition}[Modularity]
  \label{def:modular}
  A function $f: 2^V \rightarrow \bbR$ is \emRed{modular} if for any $A \subseteq B \subset V$, and $v \in V\backslash B$, we have that:
  \begin{equation}
    \label{eq:modular}
    f(A + v) - f(A) = f(B + v) - f(B).
  \end{equation}
\end{definition}
Notably, a modular function $f$ can always be written as
$$f(S) = f(\emptyset) + \sum_{v\in S} \left( f(\{v\}) - f(\emptyset) \right)$$
for any $S \subseteq V$.

If we further assume $f(\emptyset) = 0$ (in this case, we call $f$ \emRed{normalized}), we have a simplified expression,

$$f(S) = \sum_{v\in S} f(\{v\}).$$


Modularity can be useful in our discussion of submodularity, because one can use modular functions to construct submodular functions with desired properties in their applications. Examples can be found in e.g. \cite{LB11,LB11word}.




A supermodular function is defined by flipping the inequality sign in the definition of a submodular function. Formally,
\begin{definition}[Supermodularity]
  \label{def:supermodular}
  A function $f: 2^V \rightarrow \bbR$ is \emRed{modular} if for any $A \subseteq B \subset V$, and $v \in V\backslash B$, we have that:
  \begin{equation}
    \label{eq:submodular}
    f(A + v) - f(A) \leq f(B + v) - f(B).
  \end{equation}
\end{definition}

We will focus on submodular functions because a function is supermodular if and only if its negative is submodular. 



\subsection{Properties}
Like convex and concave functions, submodular functions have many nice properties. Lov{\'a}sz's description of convex functions \cite{L83} can be viewed as accurate comments on submodularity:
\begin{quote}
 - Convex functions occur in many mathematical models in economy,
engineering, and other sciences. Convexity is a very natural property
of various functions and domains occurring in such models; quite
often the only non-trivial property which can be stated in general.

- Convexity is preserved under many natural operations and
transformations, and thereby the effective range of results can be
extended, elegant proof techniques can be developed as well as
unforeseen applications of certain results can be given.

- Convex functions and domains exhibit sufficient structure so that a
mathematically beautiful and practically useful theory can be
developed.

- There are theoretically and practically (reasonably) efficient methods
to find the minimum of a convex function.
\end{quote}

We survey several useful properties which can be useful in our later section. More properties of submodularity can be found in e.g. \cite{B14,F05}.





Submodularity is close under addition,
\begin{property}
  \label{prop:addition}
  Let $f_1, f_2: 2^V \rightarrow \bbR$ be two submodular functions. Then 
  $$f: 2^V\rightarrow \bbR~{with}~ f(A) = \alpha f_1(A) + \beta f_2(A)$$ 
is submodular for any fixed $\alpha, \beta \in \bbR^+$.
\end{property}


Adding a modular function does not break submodularity,
\begin{property}
  \label{prop:modular}
  Let $f_1, f_2: 2^V \rightarrow \bbR$, $f_1$ is submodular and $f_2$ is modular. Then
  $$f: 2^V \rightarrow \bbR~\text{with}~ f(A) = f_1(A) + \alpha f_2(A)$$
is submodular for any fixed $\alpha \in \bbR$.
\end{property}

Submodularity is preserved under restriction,
\begin{property}
  \label{prop:restriction}
  Let $f: 2^V \rightarrow \bbR$ be a submodular function. Let $S\subseteq V$ be a fixed set. Then
$$f':2^V \rightarrow \bbR~{with}~f'(A) = f(A\cap S)$$
is submodular.
\end{property}

As a direct implication of Property \ref{prop:addition} and Property \ref{prop:restriction}, we have the following more general result,
\begin{property}
Let $f:2^V \rightarrow \bbR$ be a submodular function, $\calC = \{C_1, C_2, \ldots, C_k\}$ be a collection of subsets of $V$ (i.e. each $C_i \subseteq V$). Then
$$f':2^V \rightarrow \bbR~{with}~f'(A) = \sum_{C\in\calC}f(A\cap C)$$ 
is submodular.
\end{property}
This property can be useful in graphical models and image processing. \chensays{TODO: show examples}


Following property can be useful when we show that the objective function of k-medoid problem is supermodular,
\begin{property}
Consider $V$ as a set of indices. Let $\mathbf{c}\in \bbR^V$ be a fixed vector, $c_i$ be its $i$th coordinate. Then 
$$f:2^V \rightarrow \bbR~{with}~ f(A) = \max_{j\in A}c_i$$ 
is submodular.
\end{property}

We can use non-negative modular function and a concave function to construct submodular functions,
\begin{property}
  Let $m: 2^V \rightarrow \bbR^+$ be a modular function, and $f$ a concave function over $\bbR$. Then
$$f: 2^V \rightarrow \bbR ~{with}~ f(A) = g(m(A))$$
is submodular.
\end{property}

Before introducing the next property, we define the monotonitcity of set function,
\begin{definition}[Monotonitcity]
  An set function $f: 2^V \rightarrow  \bbR$ is said to be monotone non-decreasing if for any $A\subseteq B \subseteq V$, $f(A) \leq f(B)$. Monotone non-increasing function can be defined similarly.
\end{definition}

\begin{property}
  Let $f, g: 2^V \rightarrow \bbR$ be two submodular functions. If $(f - g)(\cdot)$ is either monotone non-decreasing or monotone non-increasing, then $f: 2^V \rightarrow \bbR$ with
$$f(A) = \min(f(A), g(A))$$
is submodular.
\end{property}



\subsection{Constraints}
Now we discuss the constraints in submodular optimization problems. A submodular maximization problem usually has the following form,
\begin{equation}
  \label{eq:optimization}
  \arg\max_{I\in\calI} f(I)
\end{equation}

where $f$ is a submodular function and $\calI \subseteq 2^V$ is the collection of all feasible solutions. We call $\calI$ the \emRed{constraint} of the optimization problem. The structure of $\calI$ plays a crucial role in submodular optimization. Different constraints have different hardness results, normally the difficulty increases when the constraint becomes more general. Ordered by their generality, we will introduce cardinality constraint, matroid, p-system and p-matchoid.

\subsubsection{Cardinality Constraint}
Cardinality constraint is perhaps the most straightforward constraint we would discuss in this survey. Efficient algorithms have been developed for finding or approximating the optimal solution of (\ref{eq:optimization}). There are also a lot of discussions on optimization subject to cardinality constraint, in both streaming and distributed setting. 

A cardinality constraint is parameterized with a fixed constant $k \in \bbZ^+$. It is simply defined as $\calI = \{A \subseteq V ~|~ |V| \leq k\}$, i.e. all subsets of $V$ with size no larger than $k$. Cardinality constraint is arguably the most popular constraint, and it occurs everywhere. For example, in k-medoid clustering, we want to find a set $S$ of \emph{at most} $k$ points, that minimizes the total distance of all points to $S$.  


\subsubsection{Matroid}
Informally, a \emRed{Matroid} is the abstraction of the \emph{independence} concept in linear algebra. In fact there are so many results around Matroid and the Matroid itself becomes a subfield of algebra. We cover some basics of Matroid theory and from which readers can easily see how powerful this concept is. 

Before discussing the concept of a Matroid, we briefly review the independence concept from linear algebra. For simplicity, let us just consider $\bbR^d$ instead of a general linear space. A subset $S$ of $\bbR^d$ is said to be \emph{independent} if there does not exist any $\mathbf{x}\in S$ such that $\mathbf{x}$ can be represented by linear combination of vectors in $S\backslash\{\mathbf{x}\}$. 

Let $\calI = \{S \subseteq \bbR^d~|~S ~\text{is independent}~\}$, i.e. only a independent set can be considered feasible. From what we learn in college linear algebra course, we know $\calI$ has the following property,
\begin{itemize}
\label{item:independence}
\item $\emptyset \in \calI$
\item $\forall I \in \calI$, $J\subseteq I \implies J\in \calI$
\item $\forall I, J \in \calI,$ with $|I| = |J| + 1$,  then $\exists \mathbf{x}\in I\backslash J$ such that $J \cup \{\mathbf{x}\}\in \calI$ 
\end{itemize}
Even for the ``trivial'' size function $f: 2^V \rightarrow \bbZ$ with $f(A) = |A|$, optimizing $\arg\max_{I\in\calI} f(S)$ would have tremendous applications because its optimal solution is a base of the vector space. We will see shortly how this optimization problem has direct connection with \emph{Maximum Spanning Tree} problem. If we somehow generalize the definition of independence, we may be able to model a much more larger class of problems into the form (\ref{eq:optimization}). 

It turns out that the properties of $\calI$ we just described are sufficient to give a meaningful definition for Matroid. Formally, 
\begin{definition}[Matroid]
\label{def:matroid}
  A set system $(V, \calI)$ is a Matroid if it has the following properties,
  \begin{enumerate}
  \item $\emptyset \in \calI$
  \item $\forall I \in \calI$, $J\subseteq I \implies J\in \calI$
  \item $\forall I, J \in \calI,$ with $|I| = |J| + 1$,  then $\exists~ x\in I\backslash J$ such that $J \cup \{x\}\in \calI$ 
  \end{enumerate} 
\end{definition}
Note that, unlike in the $\bbR^d$ case, we restrict on a finite set $V$.\chensays{is it necessary?} 




\subsection{Algorithms for Submodular Maximization}
Greey algorithm guarantee is for normalized, monotone submodular maximization under cardinality constraint.  
Moreover, no polynomial time algorithm can provide a better approximation guarantee unless P = NP \cite{F98}.








